{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.4",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "snake -fruit-part3.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wawan2/snake_fruit/blob/master/snake_fruit_part3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwD0mLepep6u",
        "colab_type": "text"
      },
      "source": [
        "persiapan dataset, dapat melalui kaggle atau google drive\n",
        "langkah pertama menggunakan dataset dari google drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GYaDwyfnfAgQ",
        "colab_type": "text"
      },
      "source": [
        "import dataset dari kaggle\n",
        "1. unggah file kaggle.json yang dibuat dari api key kaggle\n",
        "2. download dataset dari kaggle dengan menggunakan API command\n",
        "3. unzip file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZvDhxTBe_ve",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.upload() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3ZT79LrfIPB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -q kaggle\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!ls ~/.kaggle\n",
        "!chmod 600 /root/.kaggle/kaggle.jso"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pq--9FVWf4Bx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!kaggle datasets download -d wawan12/snakefruitpart3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ChX8mf0Af6Wp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip snakefruitpart3.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7w-cmTDD5CTd",
        "colab_type": "text"
      },
      "source": [
        "# Import dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNxP3YTj5KaX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install pydicom"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKclvpjQQL56",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install Keras==2.1.5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORihK2L4OrA1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44fz7styPtRC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJqhUW-nOyX9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip uninstall tensorflow"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YuDoqpoxO2WC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip3 install tensorflow==1.7.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "PtrN7PJL5CTe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import random\n",
        "import math\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "import pydicom\n",
        "from imgaug import augmenters as iaa\n",
        "from tqdm import tqdm\n",
        "import pandas as pd \n",
        "import glob \n",
        "import skimage.draw\n",
        "import tensorflow as tf\n",
        "import keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zN4ljm15CTi",
        "colab_type": "text"
      },
      "source": [
        "# Download library"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QxEbh3BnQpL-",
        "colab_type": "text"
      },
      "source": [
        "download datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9KfWTWFQh_N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!git clone https://github.com/wawan2/snake_fruit.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2BWE7CCQpsK",
        "colab_type": "text"
      },
      "source": [
        "download library mask rcnn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "MORfcRIH5CTj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://www.github.com/matterport/Mask_RCNN.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true,
        "id": "Gf46w9zN5CTm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir('/content/drive/My Drive/Mask_RCNN/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "d-MixcDp5CTp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ROOT_DIR = '/content/drive/My Drive/Mask_RCNN/dataset/'\n",
        "#ROOT_DIR = '/content/drive/My Drive/snake_fruit'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "io-xA4ubQ6Cg",
        "colab_type": "text"
      },
      "source": [
        "extract dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8eoyO039oey",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import os\n",
        "#from zipfile import ZipFile\n",
        "\n",
        "#%cd /content/\n",
        "#ds = ZipFile('dataset.zip')\n",
        "#ds.extractall()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0taWBti8bb0u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#%cd /Mask_RCNN/kaggle/dataset/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RT-SuK3K5CTs",
        "colab_type": "text"
      },
      "source": [
        "# Import MaskRCNN dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "C4WOVCnL5CTt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sys.path.append(os.path.join(ROOT_DIR, '/content/drive/My Drive/Mask_RCNN'))  # To find local version of the library\n",
        "from mrcnn.config import Config\n",
        "from mrcnn import utils\n",
        "import mrcnn.model as modellib\n",
        "from mrcnn import visualize\n",
        "from mrcnn.model import log"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7MVpdg-5CTw",
        "colab_type": "text"
      },
      "source": [
        "# Create Configuration class for Detector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "mkoyvouN5CTw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The following parameters have been selected to reduce running time for demonstration purposes \n",
        "# These are not optimal \n",
        "\n",
        "class DetectorConfig(Config):\n",
        "    \"\"\"Configuration for training pneumonia detection on the RSNA pneumonia dataset.\n",
        "    Overrides values in the base Config class.\n",
        "    \"\"\"\n",
        "    \n",
        "    NAME = 'fruits'\n",
        "    \n",
        "    GPU_COUNT = 1\n",
        "    IMAGES_PER_GPU = 8\n",
        "    \n",
        "    BACKBONE = 'resnet50'\n",
        "    \n",
        "    NUM_CLASSES = 3  # background + 3 fruit classes\n",
        "    \n",
        "    IMAGE_MIN_DIM = 256\n",
        "    IMAGE_MAX_DIM = 256\n",
        "    RPN_ANCHOR_SCALES = (16, 32, 64, 128, 256)\n",
        "    TRAIN_ROIS_PER_IMAGE = 32\n",
        "\n",
        "    STEPS_PER_EPOCH = 25\n",
        "    \n",
        "config = DetectorConfig()\n",
        "config.display()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHfVeRFB5CT1",
        "colab_type": "text"
      },
      "source": [
        "# Extend existing Dataset class to customize methods"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "MPan1YPr5CT1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DetectorDataset(utils.Dataset):\n",
        "    \"\"\"Dataset class for training pneumonia detection on the RSNA pneumonia dataset.\n",
        "    \"\"\"\n",
        "    \n",
        "    def load_labels(self, labels_list):\n",
        "        for i, label in enumerate(labels_list):\n",
        "            self.add_class('fruits', i + 1, label)\n",
        "            \n",
        "    def load_dataset(self, images_obj):\n",
        "        for image_obj in images_obj:\n",
        "            image_id = image_obj['image_id']\n",
        "            image_path = image_obj['image_path']\n",
        "            num_ids = image_obj['num_ids']\n",
        "            polygons = image_obj['polygons']\n",
        "            width = image_obj['width']\n",
        "            height = image_obj['height']\n",
        "            self.add_image(\"fruits\", image_id=image_id, path=image_path,\n",
        "                           width=width, height=height, polygons=polygons,num_ids=num_ids)\n",
        "            \n",
        "    def image_reference(self, image_id):\n",
        "        info = self.image_info[image_id]\n",
        "        return info['path']\n",
        "\n",
        "    def draw_shape(self, image, shape, dims, color):\n",
        "        \"\"\"Draws a shape from the given specs.\"\"\"\n",
        "        # Get the center x, y and the size s\n",
        "        x, y, s = dims\n",
        "        if shape == 'square':\n",
        "            cv2.rectangle(image, (x-s, y-s), (x+s, y+s), color, -1)\n",
        "        elif shape == \"circle\":\n",
        "            cv2.circle(image, (x, y), s, color, -1)\n",
        "        elif shape == \"triangle\":\n",
        "            points = np.array([[(x, y-s),\n",
        "                                (x-s/math.sin(math.radians(60)), y+s),\n",
        "                                (x+s/math.sin(math.radians(60)), y+s),\n",
        "                                ]], dtype=np.int32)\n",
        "            cv2.fillPoly(image, points, color)\n",
        "        return image\n",
        "\n",
        "    def load_mask(self, image_id):\n",
        "        \"\"\"Generate instance masks for an image.\n",
        "       Returns:\n",
        "        masks: A bool array of shape [height, width, instance count] with\n",
        "            one mask per instance.\n",
        "        class_ids: a 1D array of class IDs of the instance masks.\n",
        "        \"\"\"\n",
        "        info = self.image_info[image_id]\n",
        "        num_ids = info['num_ids']\n",
        "        mask = np.zeros([info[\"height\"], info[\"width\"], len(info[\"polygons\"])],\n",
        "                        dtype=np.uint8)\n",
        "\n",
        "        for i, p in enumerate(info[\"polygons\"]):\n",
        "            # Get indexes of pixels inside the polygon and set them to 1\n",
        "            rr, cc = skimage.draw.polygon(p['all_points_y'], p['all_points_x'])\n",
        "            mask[rr, cc, i] = 1\n",
        "\n",
        "        num_ids = np.array(num_ids, dtype=np.int32)\n",
        "        return mask, num_ids"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTZt7LFa5CT4",
        "colab_type": "text"
      },
      "source": [
        "# Set root directory for training and test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "7yKfyOrx5CT4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_image_path = os.path.join('/content/drive/My Drive/Mask_RCNN/dataset', 'train_zip')\n",
        "#/content/drive/My Drive/Mask_RCNN/dataset\n",
        "test_image_path = os.path.join('/content/drive/My Drive/Mask_RCNN/dataset', 'test_zip')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mesRWRZ55CT7",
        "colab_type": "text"
      },
      "source": [
        "# Convert xml file information to dict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZNQxUtX5CT7",
        "colab_type": "text"
      },
      "source": [
        "## Download xmltodict helper dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "cjGtJQac5CT8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install xmltodict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GYgHxeGu5CT_",
        "colab_type": "text"
      },
      "source": [
        "## Define labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "6lSAJxi85CT_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = [\"Normal\", \"Reject\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YnrrCXnb5CUB",
        "colab_type": "text"
      },
      "source": [
        "## Parse a single annoation\n",
        "- Extract the dict object and convert it into cocos format\n",
        "\n",
        "Example of format:\n",
        "{\n",
        "    \"all_points_x\": [...],\n",
        "    \"all_points_y\": [...],\n",
        "    \"num_id\": 3\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "yC-92ZAo5CUC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def parse_single_annotation(label_obj):\n",
        "    #print(label_obj)\n",
        "    name = label_obj['name']\n",
        "    # Get label\n",
        "    num_id = labels.index(name) + 1\n",
        "    bb_box = label_obj['bndbox']\n",
        "    # Extract the xmin xmax ymin and ymax of bounding box\n",
        "    xmin = int(bb_box['xmin'])\n",
        "    xmax = int(bb_box['xmax'])\n",
        "    ymin = int(bb_box['ymin'])\n",
        "    ymax = int(bb_box['ymax'])\n",
        "    # Convert it into polygon format. So we need 5 points for both x and y\n",
        "    all_points_x = [xmin, xmax, xmax, xmin, xmin]\n",
        "    all_points_y = [ymin, ymin, ymax, ymax, ymin]\n",
        "    return all_points_x, all_points_y, num_id\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2aFFUKw5CUF",
        "colab_type": "text"
      },
      "source": [
        "## Parse the images and annotations and it in a single array"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Zjf7tP3m5CUG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import xmltodict\n",
        "import json\n",
        "train_images = []\n",
        "def transform_annotations(image_path):\n",
        "    # Start the index from 100\n",
        "    curr_idx = 101000\n",
        "    images_list = []\n",
        "    # List the files in the training or test path\n",
        "    for i in os.listdir(os.path.join(image_path)):\n",
        "        # Get the image path\n",
        "        img_path = os.path.join(image_path, i)\n",
        "        split_img_path = i.split('.')\n",
        "        # check if the file is a .jpg ext. We ignore .xml file as they will be parsed based on .jpg file name\n",
        "        if split_img_path[1] == 'jpg':\n",
        "            # Define dict key value pair required in coco dataset\n",
        "            polygons = []\n",
        "            num_ids = []\n",
        "            # Read the image file \n",
        "            file_data = cv2.imread(img_path)\n",
        "            # Get the heigh and width. OpenCV shape is in the format h, w, depth\n",
        "            height, width, _ = file_data.shape\n",
        "            # Open the xml file which has the same name of the image we have opened for this iteration\n",
        "            with open(os.path.join(image_path, split_img_path[0] + '.xml')) as fd:\n",
        "                # Load the xml -> convert xml to dict -> convert to json\n",
        "                bb_file = json.loads(json.dumps(xmltodict.parse(fd.read())))\n",
        "                # There are two case - bb_file['annotation']['object'] can exist as a single dict or as a list of dict.\n",
        "                # Thus, we need to do a check to see whether it is a list or not.\n",
        "                # If the value is a data type of list:\n",
        "                if isinstance(bb_file['annotation']['object'], list):\n",
        "                    # Loop through each dict in the list\n",
        "                    for obj in bb_file['annotation']['object']:\n",
        "                        # Parse each annotation individually\n",
        "                        all_points_x, all_points_y, num_id = parse_single_annotation(obj)\n",
        "                        # Append the points into polygon list\n",
        "                        polygons.append({\n",
        "                            'all_points_x': all_points_x,\n",
        "                            'all_points_y': all_points_y\n",
        "                        })\n",
        "                        # Append the id into the num_ids list\n",
        "                        num_ids.append(num_id)\n",
        "                # If the ['object'] key only contains a dict value\n",
        "                else:\n",
        "                    # We just need to parse a single annotation\n",
        "                    all_points_x, all_points_y, num_id = parse_single_annotation(bb_file['annotation']['object'])\n",
        "                    # Append it into polygon and num_ids list\n",
        "                    polygons.append({\n",
        "                        'all_points_x': all_points_x,\n",
        "                        'all_points_y': all_points_y\n",
        "                    })\n",
        "                    num_ids.append(num_id)\n",
        "            # For this image, we need to create a dict to represent it and all the corresponding annotations represented by polygons and num_ids key list\n",
        "            image_label = {\n",
        "                'image_path': img_path,\n",
        "                'image_id': curr_idx,\n",
        "                'polygons': polygons,\n",
        "                'num_ids': num_ids,\n",
        "                'height': height,\n",
        "                'width': width\n",
        "            }\n",
        "            curr_idx = curr_idx + 1\n",
        "            # Append it into the images_list\n",
        "            images_list.append(image_label)\n",
        "    return images_list\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FRb6YoX5CUI",
        "colab_type": "text"
      },
      "source": [
        "# Store annotations into the respective train and test dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcdlak8M5CUJ",
        "colab_type": "text"
      },
      "source": [
        "## Load the training dataset and prepare"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "2BQJ4obF5CUJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_images = transform_annotations(os.path.join(train_image_path, 'train'))\n",
        "print(train_images[0:4])\n",
        "dataset_train = DetectorDataset()\n",
        "dataset_train.load_labels(labels)\n",
        "dataset_train.load_dataset(train_images)\n",
        "dataset_train.prepare()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QujljWNl5CUM",
        "colab_type": "text"
      },
      "source": [
        "## Load the test dataset and prepare "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "xh3G6Wdv5CUM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_images = transform_annotations(os.path.join(test_image_path, 'test'))\n",
        "#print(test_images[0:4])\n",
        "dataset_val = DetectorDataset()\n",
        "dataset_val.load_labels(labels)\n",
        "dataset_val.load_dataset(test_images)\n",
        "dataset_val.prepare()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCzwntgk5CUQ",
        "colab_type": "text"
      },
      "source": [
        "## Load and visualize the pixel mask for the first 10 objects"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "KPjY_wJ35CUR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from mrcnn import visualize\n",
        "for i in range(10):\n",
        "    image_id = train_images[i]['image_id']\n",
        "    mask, num_id = dataset_train.load_mask(i)\n",
        "    img_data = cv2.imread(train_images[i]['image_path'])\n",
        "    num_id = [x - 1 for x in num_id]\n",
        "    visualize.display_top_masks(img_data, mask, num_id, labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clTsRo1O5CUU",
        "colab_type": "text"
      },
      "source": [
        "# Start training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1LW9mm865CUV",
        "colab_type": "text"
      },
      "source": [
        "## Download the coco weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-db_fckIjjQe",
        "colab": {}
      },
      "source": [
        "#%cd /content/Mask_RCNN/kaggle/project/mask_rcnn_coco.h5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "hLTqnuPG5CUV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cd dataset && mkdir project\n",
        "#!cd Mask_RCNN/kaggle/project\n",
        "sys.path.append(ROOT_DIR)\n",
        "MODEL_DIR = os.path.join(ROOT_DIR, 'logs')\n",
        "# Local path to trained weights file\n",
        "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
        "# Download COCO trained weights from Releases if needed\n",
        "if not os.path.exists(COCO_MODEL_PATH):\n",
        "    utils.download_trained_weights(COCO_MODEL_PATH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0Q9f1zq5CUY",
        "colab_type": "text"
      },
      "source": [
        "## Create the model with the specified configuration defined at the top of the file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Xk8pEs2w5CUY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create model in training mode\n",
        "model = modellib.MaskRCNN(mode=\"training\", config=config,\n",
        "                          model_dir=MODEL_DIR)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6L4sl_dz5CUc",
        "colab_type": "text"
      },
      "source": [
        "## Load the weights of the COCO dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "_53mjheS5CUd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Which weights to start with?\n",
        "init_with = \"coco\"  # imagenet, coco, or last\n",
        "\n",
        "if init_with == \"imagenet\":\n",
        "    model.load_weights(model.get_imagenet_weights(), by_name=True)\n",
        "elif init_with == \"coco\":\n",
        "    # Load weights trained on MS COCO, but skip layers that\n",
        "    # are different due to the different number of classes\n",
        "    # See README for instructions to download the COCO weights\n",
        "    model.load_weights(COCO_MODEL_PATH, by_name=True,\n",
        "                       exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \n",
        "                                \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
        "elif init_with == \"last\":\n",
        "    # Load the last model you trained and continue training\n",
        "    model.load_weights(model.find_last(), by_name=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "702eigA7Vxx9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -U tensorboard-plugin-wit"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkCaj2olV7bJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir logs/scalars"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ATojENBl5CUf",
        "colab_type": "text"
      },
      "source": [
        "## Now we can start training the actual dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "2zQpwFG85CUf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train the head branches\n",
        "# Passing layers=\"heads\" freezes all layers except the head\n",
        "# layers. You can also pass a regular expression to select\n",
        "# which layers to train by name pattern.\n",
        "model.train(dataset_train, dataset_val, \n",
        "            learning_rate=config.LEARNING_RATE, \n",
        "            epochs=10, \n",
        "            layers='heads')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FALsAHm3amBY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cyh66ympO6xU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import * \n",
        "filepath = \" /content/drive/My Drive/Mask_RCNN/dataset/logs/fruits20200504T1546/mask_rcnn_fruits_{epoch:04d}.h5:{epoch:03d}-val_acc:{val_acc:.3f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "callbacks_list = [checkpoint]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XlRwvv4N7H_J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorboard — logdir logs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5wdDOoj7v1z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard.notebook\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
        "%tensorboard — logdir logs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XS3MqMrA5CUi",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "# Visualize image output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93REILeuLvFY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#image_id = random.choice(dataset.image_ids)\n",
        "for image_id in dataset.image_ids:\n",
        "  image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
        "      modellib.load_image_gt(dataset, config, image_id, use_mini_mask=False)\n",
        "  info = dataset.image_info[image_id]\n",
        "  print(\"image ID: {}.{} ({}) {}\".format(info[\"source\"], info[\"id\"], image_id, \n",
        "                                         dataset.image_reference(image_id)))\n",
        "\n",
        "  # Run object detection\n",
        "  results = model.detect([image], verbose=1)\n",
        "\n",
        "  # Display results\n",
        "  ax = get_ax(1)\n",
        "  r = results[0]\n",
        "  visualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], \n",
        "                              dataset.class_names, r['scores'], ax=ax,\n",
        "                              title='Predictions', info['id'])\n",
        "  log(\"gt_class_id\", gt_class_id)\n",
        "  log(\"gt_bbox\", gt_bbox)\n",
        "  log(\"gt_mask\", gt_mask)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUFh_OfllYP4",
        "colab_type": "text"
      },
      "source": [
        "**EVALUTION**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjpeHz_bVf-z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compute VOC-Style mAP @ IoU=0.5\n",
        "# Running on 30 images. Increase for better accuracy.\n",
        "image_ids = np.random.choice(dataset_val.image_ids, 160)\n",
        "APs = []\n",
        "for image_id in image_ids:\n",
        "    # Load image and ground truth data\n",
        "    image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
        "        modellib.load_image_gt(dataset_val, inference_config,\n",
        "                               image_id, use_mini_mask=False)\n",
        "    molded_images = np.expand_dims(modellib.mold_image(image, inference_config), 0)\n",
        "    # Run object detection\n",
        "    results = model.detect([image], verbose=0)\n",
        "    r = results[0]\n",
        "    # Compute AP\n",
        "    AP, precisions, recalls, overlaps =\\\n",
        "        utils.compute_ap(gt_bbox, gt_class_id, gt_mask,\n",
        "                         r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'])\n",
        "    APs.append(AP)\n",
        "    \n",
        "print(\"mAP: \", np.mean(APs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "eS-ffUmz5CUj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.listdir(MODEL_DIR)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "_h_LnNUG5CUl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dir_names = os.listdir(MODEL_DIR)\n",
        "dir_names = sorted(dir_names)\n",
        "\n",
        "fps = []\n",
        "# Pick last directory\n",
        "for d in dir_names: \n",
        "    dir_name = os.path.join(MODEL_DIR, d)\n",
        "    # Find the last checkpoint\n",
        "    checkpoints = next(os.walk(dir_name))[2]\n",
        "    checkpoints = filter(lambda f: f.startswith(\"mask_rcnn\"), checkpoints)\n",
        "    checkpoints = sorted(checkpoints)\n",
        "    if not checkpoints:\n",
        "        print('No weight files in {}'.format(dir_name))\n",
        "    else: \n",
        "      \n",
        "      checkpoint = os.path.join(dir_name, checkpoints[-1])\n",
        "      fps.append(checkpoint)\n",
        "\n",
        "model_path = sorted(fps)[-1]\n",
        "print('Found model {}'.format(model_path))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j48j6d3D5CUp",
        "colab_type": "text"
      },
      "source": [
        "# Create inference configuration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "5ldsqP9J5CUq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class InferenceConfig(DetectorConfig):\n",
        "    GPU_COUNT = 1\n",
        "    IMAGES_PER_GPU = 1\n",
        "\n",
        "inference_config = InferenceConfig()\n",
        "\n",
        "# Recreate the model in inference mode\n",
        "model = modellib.MaskRCNN(mode='inference', \n",
        "                          config=inference_config,\n",
        "                          model_dir=ROOT_DIR)\n",
        "\n",
        "# Load trained weights (fill in path to trained weights here)\n",
        "assert model_path != \"\", \"Provide path to trained weights\"\n",
        "print(\"Loading weights from \", model_path)\n",
        "model.load_weights(model_path, by_name=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "a7vIOdy15CUs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# set color for class\n",
        "def get_colors_for_class_ids(class_ids):\n",
        "    class_ids = [x - 1 for x in class_ids]\n",
        "    colors = []\n",
        "    for class_id in class_ids:\n",
        "        if class_id == 1:\n",
        "            colors.append((.941, .204, .204))\n",
        "    return colors"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUiPFFAo5CUu",
        "colab_type": "text"
      },
      "source": [
        "# Predict output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "B18YWQK65CUv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Show few example of ground truth vs. predictions on the validation dataset \n",
        "dataset = dataset_val\n",
        "fig = plt.figure(figsize=(10, 10))\n",
        "start_idx = 0\n",
        "for i in range(start_idx, start_idx + 5):\n",
        "    \n",
        "    image_id = random.choice(dataset.image_ids)\n",
        "    \n",
        "    original_image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
        "        modellib.load_image_gt(dataset_val, inference_config, \n",
        "                               image_id, use_mini_mask=False)\n",
        "    plt.subplot(6, 2, 2*(i-start_idx) + 1)\n",
        "    visualize.display_instances(original_image, gt_bbox, gt_mask, gt_class_id, \n",
        "                                dataset.class_names,\n",
        "                                colors=get_colors_for_class_ids(gt_class_id), ax=fig.axes[-1])\n",
        "    \n",
        "    plt.subplot(6, 2, 2*(i-start_idx) + 2)\n",
        "    results = model.detect([original_image]) #, verbose=1)\n",
        "    r = results[0]\n",
        "    visualize.display_instances(original_image, r['rois'], r['masks'], r['class_ids'], \n",
        "                                dataset.class_names, r['scores'], \n",
        "                                colors=get_colors_for_class_ids(r['class_ids']), ax=fig.axes[-1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "tVKPP9Gf5CUx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "0BPeHHsS5CU0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "v9d4PPS55CU3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}